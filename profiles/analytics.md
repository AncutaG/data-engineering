## Profiles
 - Infra
 - Data
 - Analytics

### Infra Engineering

Teko is looking for a highly motivated hands-on Infra - DevOps engineer. This position is responsible for designing and implementing a Kubernetes cluster which will support a number of analytical and storage services (mainly Spark, Cassandra, Redis, ELK, Prometheus). Youll be collaborating closely with our engineers and must be able to work efficiently across various teams.

#### Responsibilities
 - Collaborate with multiple teams and build automated solutions.
 - Build automation to install, manage & operate Kubernetes Cluster Setup.
 - Manage and control kubernetes storage, compute and service resources.
 - Build and Deploy APIs and tools to efficiently manage Kubernetes application of the cluster.

#### Basic Qualifications
 - BS in Computer Science or similar field of study
 - Very solid experience of Linux (kernel, filesystem, network, devices)
 - Extended experience of software development (Python, Ruby, Bash) and CI/CD pipelines
 - Extended experience in infrastructure automation (packer/ansible/terraform)
 - Experience running container applications (docker)
 - Experience monitoring and tuning linux applications and services
 - Experience with Kubernetes.
 - Experience with Private cloud (vmware/openstack) is a plus
 - Experience with Agile and Scrum

#### Preferred Qualifications
Excellent verbal and written communication skills; strong attention to detail
Passion to automate more, learn new software tools and technologies
Natural aptitude for both teaching and learning from others in a collaborative team environment

#### Test
Build a setup to deploy Cassandra on kubernetes.  
Bonus: expose the setup with a RESTful API.

### Data Engineering

Teko is looking for a highly motivated hands-on Data engineer. This position is responsible for designing and implementing cluster computing data systems. You'll be collaborating closely with our engineers and must be able to work efficiently across various teams.

#### Responsibilities
 - Collaborate with multiple teams and build Spark and Storage clusters.
 - Build automation to install, manage & operate Spark, Redis, Casandra, ELK, Prometheus, Minio, Kafka.
 - Manage, backup and monitor Storage services and filesystems like S3, Cassandra and Redis Tables, and object stores for data analytics
 - Understand, debug and patch big data files and objets in multiple formats (Parquet, HDF, Arrow)
 - Build, maintain and deploy data science frameworks

#### Qualifications
 - BS in Computer Science or similar field of study
 - Very solid experience of Big Data Tools and Software amd Libraries
 - Extended experience of software development (Python, Scala)
 - Extended experience in Jupyter ecosystem
 - Experience running SQL in different flavours (Spark, Cassandra, RDBMS)
 - Experience monitoring and tuning big data applications and services
 - Experience with distributed computing
 - Experience with Tensorflow
 - Experience with Concourse is a plus
 - Experience with Agile and Scrum

#### Test
Download the dataset of taxi trips in New York  https://www.kaggle.com/kentonnlp/2014-new-york-city-taxi-trips
Build a data pipeline for analytics, produce the results in ELK.
Bonus: Automate the pipeline with Concourse.

### Data Engineering

Teko is looking for a highly motivated hands-on Data engineer. This position is responsible for designing and implementing cluster computing data systems. You'll be collaborating closely with our engineers and must be able to work efficiently across various teams.

#### Responsibilities
 - Collaborate with multiple teams and build Spark and Storage clusters.
 - Build automation to install, manage & operate Spark, Redis, Casandra, ELK, Prometheus, Minio, Kafka.
 - Manage, backup and monitor Storage services and filesystems like S3, Cassandra and Redis Tables, and object stores for data analytics
 - Understand, debug and patch big data files and objets in multiple formats (Parquet, HDF, Arrow)
 - Build, maintain and deploy data science frameworks

#### Qualifications
 - BS in Computer Science or similar field of study
 - Very solid experience of Big Data Tools and Software amd Libraries
 - Extended experience of software development (Python, Scala)
 - Extended experience in Jupyter ecosystem
 - Experience running SQL in different flavours (Spark, Cassandra, RDBMS)
 - Experience monitoring and tuning big data applications and services
 - Experience with distributed computing
 - Experience with Tensorflow
 - Experience with Concourse is a plus
 - Experience with Agile and Scrum

#### Test
Download the dataset of taxi trips in New York  https://www.kaggle.com/kentonnlp/2014-new-york-city-taxi-trips
Build a data pipeline for analytics, produce the results in ELK.
Bonus: Automate the pipeline with Concourse.

### Analytics

Teko is looking for a highly motivated hands-on Analytics engineer. This position is responsible for designing and implementing analytics pipelines,  ETL processes, and Data Modeling using both distributed and single node libraries such as Spark, Keras, Tensorflow, Sci-kit Learn, Pandas. You'll be collaborating closely with our engineers and must be able to work efficiently across various teams.

#### Responsibilities
 - Collaborate with multiple teams and build Analytics.
 - Manage Data, groom, model and maintain semantics of data objects
 - Produce SQL and ML queries and processing
 - Build and Deploy Analytical Dashboards and APIs

#### Basic Qualifications
 - BS in Computer Science or similar field of study
 - Experience with ETL pipelines to transform data from a variety of data sources to a normalized form
 - Extended experience of software development (Python, Scala)
 - Experience with database design and SQL/NoSQL datastores
 - Experience with SQL
 - Experience with Kubernetes.
 - Experience with Private cloud (vmware/openstack) is a plus
 - Experience with Agile and Scrum

#### Preferred Qualifications
Excellent verbal and written communication skills; strong attention to detail
Passion to automate more, learn new software tools and technologies
Natural aptitude for both teaching and learning from others in a collaborative team environment

#### Test
Download the dataset of taxi trips in New York  https://www.kaggle.com/kentonnlp/2014-new-york-city-taxi-trips
Write a notebook with descriptive queries in Spark, Pandas and visualize the results (matplotlib, bokeh, holoviews, seaborn).
Bonus: Expose the result in a web dashboard using Dash (https://dash.plot.ly/)
